# ğŸ§  Suicide Mitigation Chatbot

An AI-powered chatbot designed to identify emotional distress and engage users in empathetic, human-like conversations. Built to support mental health, especially in critical situations, it uses an ensemble of **Microsoft's DialoGPT** and a custom **Seq2Seq LSTM model**.

---

## ğŸ“ Project Directory (as on your system)

```
D:\Git\Sucide_Mitigation_Chatbot
â”œâ”€â”€ .ipynb_checkpoints/
â”œâ”€â”€ .venv/                         â† Python virtual environment
â”œâ”€â”€ Data.csv                       â† Dataset used for training
â”œâ”€â”€ Ensembled_Model.ipynb          â† Notebook for ensembling models
â”œâ”€â”€ model/                         â† Folder containing the trained model files
â”œâ”€â”€ model.zip                      â† Zipped model archive (836 MB)
â”œâ”€â”€ Review_1.pptx                  â† Project presentation
â”œâ”€â”€ UI/                            â† React frontend + Flask backend
â”œâ”€â”€ Untitled-1.ipynb               â† Miscellaneous notebook
â”œâ”€â”€ Zeroth_Review.pptx            â† Initial review slides
```

---

## ğŸš€ Getting Started

### 1. Start the Flask Server

Navigate to the backend directory:

```bash
cd UI/public/flask-server
```

Run the server:

```bash
python server.py
```

> Ensure all required packages are installed:

```bash
pip install -r requirements.txt
```

---

### 2. Start the React Frontend

In a **new terminal**, run:

```bash
cd UI
yarn
yarn dev
```

The app will start on `http://localhost:3000`.

---

## ğŸ¤– Model Overview

This chatbot uses an **ensemble of two models** for generating emotionally rich and context-aware responses:

| Model             | Description                                                                 |
|------------------|-----------------------------------------------------------------------------|
| DialoGPT          | A pretrained transformer-based conversational model by Microsoft            |
| Custom Seq2Seq    | A bidirectional LSTM encoder-decoder trained on emotion-focused dialogue    |

---

### ğŸ§± Custom Seq2Seq Architecture

| Component             | Configuration                                                       |
|-----------------------|---------------------------------------------------------------------|
| `encoder_embedding`   | Embedding layer â€” 30,522 tokens, 256-dim, `padding_idx=0`           |
| `encoder_lstm`        | BiLSTM â€” input: 256, hidden: 512, `batch_first=True`                |
| `decoder_embedding`   | Embedding layer â€” 30,522 tokens, 256-dim, `padding_idx=0`           |
| `decoder_lstm`        | LSTM â€” input: 256, hidden: 1024, dropout: 0.4, `batch_first=True`   |
| `output_layer`        | Linear â€” `in_features=1024`, `out_features=30522`                   |
| `dropout`             | Dropout with `p=0.4`                                                |

> ğŸ” Bidirectional encoding captures rich context; decoder uses higher capacity for expressive responses.

---

## ğŸ’¡ Features

- ğŸ’¬ Deep conversations powered by **LSTM + DialoGPT**
- ğŸŒ Flask API for model inference
- âš›ï¸ React-based modern UI
- ğŸ§  Focus on **empathy** and **mental health**

---

## ğŸ“Š Resources

- ğŸ“ Dataset: `Data.csv`
- ğŸ“„ Presentations: `Review_1.pptx`, `Zeroth_Review.pptx`
- ğŸ“š Notebooks: `Ensembled_Model.ipynb`

---

A detailed explanation is published here<br>
<br>
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.15478579.svg)](https://doi.org/10.5281/zenodo.15478579)

---

## ğŸ¤ Contributing

Pull requests and feedback are welcome. Together, we can build technology that cares. â¤ï¸
